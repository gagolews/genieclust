% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{comparing_partitions}
\alias{comparing_partitions}
\alias{adjusted_asymmetric_accuracy}
\alias{normalized_accuracy}
\alias{pair_sets_index}
\alias{adjusted_rand_score}
\alias{rand_score}
\alias{adjusted_fm_score}
\alias{fm_score}
\alias{mi_score}
\alias{normalized_mi_score}
\alias{adjusted_mi_score}
\alias{normalized_confusion_matrix}
\alias{normalizing_permutation}
\title{External Cluster Validity Measures and Pairwise Partition Similarity Scores}
\usage{
adjusted_asymmetric_accuracy(x, y = NULL)

normalized_accuracy(x, y = NULL)

pair_sets_index(x, y = NULL, simplified = FALSE)

adjusted_rand_score(x, y = NULL)

rand_score(x, y = NULL)

adjusted_fm_score(x, y = NULL)

fm_score(x, y = NULL)

mi_score(x, y = NULL)

normalized_mi_score(x, y = NULL)

adjusted_mi_score(x, y = NULL)

normalized_confusion_matrix(x, y = NULL)

normalizing_permutation(x, y = NULL)
}
\arguments{
\item{x}{an integer vector of length n (or an object coercible to)
representing a K-partition of an n-set (e.g., a reference partition),
or a confusion matrix with K rows and L columns
(see \code{\link{table}(x, y)})}

\item{y}{an integer vector of length n (or an object coercible to)
representing an L-partition of the same set (e.g., the output of a
clustering algorithm we wish to compare with \code{x}),
or NULL (if x is an K*L confusion matrix)}

\item{whether}{to assume E=1 in the definition of the pair sets index index,
i.e., use Eq. (20) instead of (18); see (Rezaei, Franti, 2016).}
}
\value{
Each cluster validity measure is a single numeric value.

\code{normalized_confusion_matrix()} returns an integer matrix.
}
\description{
The functions described in this section quantify the similarity between
two label vectors \code{x} and \code{y} which represent two partitions
of a set of \eqn{n} elements into, respectively, \eqn{K} and \eqn{L}
nonempty and pairwise disjoint subsets.

For instance, \code{x} and \code{y} can be two clusterings
of a dataset with \eqn{n} observations specified by two vectors
of labels. These functions can be used as external cluster
validity measures, where we assume that \code{x} is
the reference (ground-truth) partition (compare Gagolewski, 2022).
}
\details{
Each index except \code{adjusted_asymmetric_accuracy()}
can act as a pairwise partition similarity score: it is symmetric,
i.e., \code{index(x, y) == index(y, x)}.

Each index except \code{mi_score()} (which computes the mutual
information score) outputs 1 given two identical partitions.
Note that partitions are always defined up to a bijection of the set of
possible labels, e.g., (1, 1, 2, 1) and (4, 4, 2, 4)
represent the same 2-partition.


\code{adjusted_asymmetric_accuracy()} (Gagolewski, 2022)
only accepts \eqn{K = L}. It is an external cluster validity measure
which assumes that the label vector \code{x} (or rows in the confusion
matrix) represents the reference (ground truth) partition.
It is a corrected-for-chance summary of the proportion of correctly
classified points in each cluster (with cluster matching based on the
solution to the maximal linear sum assignment problem;
see \code{\link{normalized_confusion_matrix}}), given by:
\eqn{(\max_\sigma \sum_{i=1}^K (c_{i, \sigma(i)}/(c_{i, 1}+...+c_{i, K})) - 1)/(K - 1)},
where \eqn{C} is the confusion matrix.

\code{normalized_accuracy()} is defined as
\eqn{(Accuracy(C_\sigma)-1/L)/(1-1/L)}, where \eqn{C_\sigma} is a version
of the confusion matrix for given \code{x} and \code{y},
\eqn{K \leq L}, with columns permuted based on the solution to the
maximal linear sum assignment problem.
The \eqn{Accuracy(C_\sigma)} part is sometimes referred to as
set-matching classification rate or pivoted accuracy.

\code{pair_sets_index()} gives the Pair Sets Index (PSI)
adjusted for chance (Rezaei, Franti, 2016), \eqn{K \leq L}.
Pairing is based on the solution to the linear sum assignment problem
of a transformed version of the confusion matrix.
Its simplified version assumes E=1 in the definition of the index,
i.e., uses Eq. (20) instead of (18).

\code{rand_score()} gives the Rand score (the "probability" of agreement
between the two partitions) and
\code{adjusted_rand_score()} is its version corrected for chance,
see (Hubert, Arabie, 1985),
its expected value is 0.0 given two independent partitions.
Due to the adjustment, the resulting index might also be negative
for some inputs.

Similarly, \code{fm_score()} gives the Fowlkes-Mallows (FM) score
and \code{adjusted_fm_score()} is its adjusted-for-chance version,
see (Hubert, Arabie, 1985).

Note that both the (unadjusted) Rand and FM scores are bounded from below
by \eqn{1/(K+1)} if \eqn{K=L}, hence their adjusted versions are preferred.

\code{mi_score()}, \code{adjusted_mi_score()} and
\code{normalized_mi_score()} are information-theoretic
scores, based on mutual information,
see the definition of \eqn{AMI_{sum}} and \eqn{NMI_{sum}}
in (Vinh et al., 2010).


\code{normalized_confusion_matrix()} computes the confusion matrix
and permutes its rows and columns so that the sum of the elements
of the main diagonal is the largest possible (by solving
the maximal assignment problem).
The function only accepts \eqn{K \leq L}.
The sole reordering of the columns of a confusion matrix can be determined
by calling \code{normalizing_permutation()}.

Also note that the built-in
\code{\link{table}()} determines the standard confusion matrix.
}
\examples{
y_true <- iris[[5]]
y_pred <- kmeans(as.matrix(iris[1:4]), 3)$cluster
adjusted_asymmetric_accuracy(y_true, y_pred)
normalized_accuracy(y_true, y_pred)
pair_sets_index(y_true, y_pred)
pair_sets_index(y_true, y_pred, simplified=TRUE)
adjusted_rand_score(y_true, y_pred)
rand_score(table(y_true, y_pred)) # the same
adjusted_fm_score(y_true, y_pred)
fm_score(y_true, y_pred)
mi_score(y_true, y_pred)
normalized_mi_score(y_true, y_pred)
adjusted_mi_score(y_true, y_pred)
normalized_confusion_matrix(y_true, y_pred)
normalizing_permutation(y_true, y_pred)

}
\references{
Gagolewski M., \emph{A Framework for Benchmarking Clustering Algorithms},
2022, \url{https://clustering-benchmarks.gagolewski.com}.

Gagolewski M., Adjusted asymmetric accuracy: An interpretable external
cluster validity measure, 2022, submitted for publication.

Hubert L., Arabie P., Comparing partitions,
\emph{Journal of Classification} 2(1), 1985, 193-218, esp. Eqs. (2) and (4).

Meila M., Heckerman D., An experimental comparison of model-based clustering
methods, \emph{Machine Learning} 42, 2001, pp. 9-29,
\doi{10.1023/A:1007648401407}.

Rezaei M., Franti P., Set matching measures for external cluster validity,
\emph{IEEE Transactions on Knowledge and Data Mining} 28(8), 2016,
2173-2186.

Steinley D., Properties of the Hubert-Arabie adjusted Rand index,
\emph{Psychological Methods} 9(3), 2004, pp. 386-396,
\doi{10.1037/1082-989X.9.3.386}.

Vinh N.X., Epps J., Bailey J.,
Information theoretic measures for clusterings comparison:
Variants, properties, normalization and correction for chance,
\emph{Journal of Machine Learning Research} 11, 2010, 2837-2854.
}
\author{
\href{https://www.gagolewski.com/}{Marek Gagolewski} and other contributors
}
\seealso{
The official online manual of \pkg{genieclust} at \url{https://genieclust.gagolewski.com/}

Gagolewski M., \pkg{genieclust}: Fast and robust hierarchical clustering, \emph{SoftwareX} 15:100722, 2021, \doi{10.1016/j.softx.2021.100722}.

}
