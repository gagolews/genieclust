

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Timings (How Fast Is It?) &mdash; genieclust 0.9.5.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />

  
  
  
  
    <link rel="canonical" href="https://genieclust.gagolewski.comweave/timings.html"/>
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Clustering with Noise Points Detection" href="noise.html" />
    <link rel="prev" title="Benchmarks (How Good Is It?)" href="benchmarks_ar.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> genieclust
          

          
          </a>

          
            
            
              <div class="version">
                0.9.5.dev0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Examples and Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="basics.html">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="sklearn_toy_example.html">Comparing Algorithms on Toy Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks_ar.html">Benchmarks (How Good Is It?)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Timings (How Fast Is It?)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#large-datasets">Large Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#timings-as-a-function-of-n-and-d">Timings as a Function of <cite>n</cite> and <cite>d</cite></a></li>
<li class="toctree-l2"><a class="reference internal" href="#timings-as-a-function-of-the-number-of-threads">Timings as a Function of the Number of Threads</a></li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="noise.html">Clustering with Noise Points Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">Example: Sparse Data and Movie Recommendation</a></li>
<li class="toctree-l1"><a class="reference internal" href="string.html">Example: String Data and Grouping of DNA</a></li>
<li class="toctree-l1"><a class="reference internal" href="r.html">R Interface Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">API Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../genieclust.html">Python Package <cite>genieclust</cite> Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rapi.html">R Package <em>genieclust</em> Reference</a></li>
</ul>
<p class="caption"><span class="caption-text">External Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/gagolews/genieclust">Source code (GitHub)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/gagolews/genieclust/issues">Issues and Splendid Ideas Tracker</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/genieclust/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cran.r-project.org/web/packages/genieclust/">CRAN</a></li>
</ul>
<p class="caption"><span class="caption-text">Appendix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmarks_details.html">Benchmarks — Detailed Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks_approx.html">Benchmarks — Approximate Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../z_bibliography.html">References</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">genieclust</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Timings (How Fast Is It?)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <div class="rst-breadcrumbs-buttons" role="navigation" aria-label="breadcrumb navigation">
      
        <a href="noise.html" class="btn btn-neutral float-right" title="Clustering with Noise Points Detection" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="benchmarks_ar.html" class="btn btn-neutral float-left" title="Benchmarks (How Good Is It?)" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
  </div>
  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="timings-how-fast-is-it">
<h1>Timings (How Fast Is It?)<a class="headerlink" href="#timings-how-fast-is-it" title="Permalink to this headline">¶</a></h1>
<p>In the <a class="reference internal" href="benchmarks_ar.html"><span class="doc">previous section</span></a> we have demonstrated
that Genie generates partitions of high <em>quality</em>. Now the crucial question is:
does it do this quickly?</p>
<p>Genie will be compared against K-means from <a class="reference external" href="https://scikit-learn.org/">scikit-learn</a>
<a class="bibtex reference internal" href="../z_bibliography.html#sklearn" id="id1">[PVG+11]</a> version 0.23.1
(<cite>sklearn.cluster.KMeans</cite>) for different number of threads
(by default it uses all available resources;
note that the number of restarts, <cite>n_init</cite>, defaults to 10)
and hierarchical agglomerative algorithms
with the centroid, median, and Ward linkage implemented in the
<a class="reference external" href="http://www.danifold.net/fastcluster.html">fastcluster</a> package
<a class="bibtex reference internal" href="../z_bibliography.html#fastclusterpkg" id="id2">[Mul13]</a>.</p>
<p>Genie, just like the single linkage, is based on a minimum spanning tree (MST) of the
pairwise distance graph of an input point set.
Given the MST (the slow part), Genie itself has <span class="math notranslate nohighlight">\(O(n \sqrt{n})\)</span> time
and <span class="math notranslate nohighlight">\(O(n)\)</span> memory complexity.
Generally, our parallelised implementation of a Jarník (Prim/Dijkstra)-like
method  <a class="bibtex reference internal" href="../z_bibliography.html#olson" id="id3">[Ols95]</a> will be called to compute an MST, which takes <span class="math notranslate nohighlight">\(O(d n^2)\)</span> time.
However, <a class="reference external" href="https://www.mlpack.org/">mlpack.emst</a> <a class="bibtex reference internal" href="../z_bibliography.html#mlpack" id="id4">[CEL+18]</a> provides a very fast
alternative in the case of Euclidean spaces of (very) low dimensionality,
see <a class="bibtex reference internal" href="../z_bibliography.html#emst" id="id5">[MRG10]</a> and the <cite>mlpack_enabled</cite> parameter, which is automatically used
for datasets with up to <span class="math notranslate nohighlight">\(d=6\)</span> features.
Moreover, in the approximate method (<cite>exact</cite> = <code class="docutils literal notranslate"><span class="pre">False</span></code>), we apply
the Kruskal algorithm on the near-neighbour graph determined
by <cite>nmslib</cite> <a class="bibtex reference internal" href="../z_bibliography.html#nmslib" id="id6">[NBMN19]</a>. Albeit this only gives <em>some</em> sort of a spanning <em>forest</em>,
such a data structure <a class="reference internal" href="benchmarks_approx.html"><span class="doc">turns out to be very suitable for our clustering task</span></a>.</p>
<p>All timings will be performed on a PC running GNU/Linux 5.4.0-40-generic #44-Ubuntu
SMP x86_64 kernel with an Intel(R) Core(TM) i7-9750H CPU &#64; 2.60GHz (12M cache, 6 cores, 12 threads)
and total memory of 16,242,084 kB.</p>
<div class="section" id="large-datasets">
<h2>Large Datasets<a class="headerlink" href="#large-datasets" title="Permalink to this headline">¶</a></h2>
<p>Let’s study the algorithm’s run times for some of the
“larger” datasets (70,000-105,600 observations,
see section on <a class="reference internal" href="benchmarks_ar.html"><span class="doc">benchmark results</span></a> for discussion)
from the
<a class="reference external" href="https://github.com/gagolews/clustering_benchmarks_v1">Benchmark Suite for Clustering Algorithms — Version 1</a>
<a class="bibtex reference internal" href="../z_bibliography.html#clustering-benchmarks-v1" id="id7">[G+20]</a>.
Features with variance of 0 were removed,
datasets were centred at <strong>0</strong> and scaled so that they have total variance of 1.
Tiny bit of Gaussian noise was added to each observation.
Clustering is performed with respect to the Euclidean distance.</p>
<p>Here are the results (in seconds) if 6 threads are requested
(except for <cite>fastcluster</cite> which is not parallelised).
For K-means, the timings are listed as a function of the number of clusters to detect,
for the other hierarchical methods the run-times are almost identical irrespective of the
partitions’ cardinality.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 21%" />
<col style="width: 10%" />
<col style="width: 5%" />
<col style="width: 32%" />
<col style="width: 11%" />
<col style="width: 10%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>dataset</p></th>
<th class="head"><p>n</p></th>
<th class="head"><p>d</p></th>
<th class="head"><p>method</p></th>
<th class="head"><p>10</p></th>
<th class="head"><p>100</p></th>
<th class="head"><p>1000</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>mnist/digits</p></td>
<td><p>70000</p></td>
<td><p>719</p></td>
<td><p>Genie_0.3</p></td>
<td><p>412.72</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>Genie_0.3_approx</p></td>
<td><p>42.77</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_centroid</p></td>
<td><p>4170.98</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_median</p></td>
<td><p>3927.93</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_ward</p></td>
<td><p>4114.05</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>sklearn_kmeans</p></td>
<td><p>26.3</p></td>
<td><p>217.62</p></td>
<td><p>1691.68</p></td>
</tr>
<tr class="row-even"><td><p>mnist/fashion</p></td>
<td><p>70000</p></td>
<td><p>784</p></td>
<td><p>Genie_0.3</p></td>
<td><p>445.81</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>Genie_0.3_approx</p></td>
<td><p>38.02</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_centroid</p></td>
<td><p>4486.32</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_median</p></td>
<td><p>4384.62</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_ward</p></td>
<td><p>4757.32</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>sklearn_kmeans</p></td>
<td><p>24.9</p></td>
<td><p>225.04</p></td>
<td><p>1745.88</p></td>
</tr>
<tr class="row-even"><td><p>sipu/worms_2</p></td>
<td><p>105600</p></td>
<td><p>2</p></td>
<td><p>Genie_0.3</p></td>
<td><p>0.57</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>Genie_0.3_approx</p></td>
<td><p>3.67</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_centroid</p></td>
<td><p>66.3</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_median</p></td>
<td><p>64.11</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_ward</p></td>
<td><p>60.92</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>sklearn_kmeans</p></td>
<td><p>0.86</p></td>
<td><p>10.96</p></td>
<td><p>111.9</p></td>
</tr>
<tr class="row-even"><td><p>sipu/worms_64</p></td>
<td><p>105000</p></td>
<td><p>64</p></td>
<td><p>Genie_0.3</p></td>
<td><p>76.7</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>Genie_0.3_approx</p></td>
<td><p>8.26</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_centroid</p></td>
<td><p>4945.91</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_median</p></td>
<td><p>2854.27</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
<td><p>fastcluster_ward</p></td>
<td><p>778.18</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td></td>
<td><p>sklearn_kmeans</p></td>
<td><p>3.35</p></td>
<td><p>37.89</p></td>
<td><p>357.84</p></td>
</tr>
</tbody>
</table>
<p>Of course, the K-means algorithm is the fastest.
However, its performance degrades as K increases. Hence, it might not be
a good choice for the so-called <em>extreme clustering</em> (compare <a class="bibtex reference internal" href="../z_bibliography.html#extreme" id="id8">[KMKM17]</a>)
problems. Most importantly, the approximate version of Genie (based on <cite>nmslib</cite>)
is only slightly slower.
The exact variant is extremely performant in Euclidean spaces of low dimensionality
(thanks to <cite>mlpack</cite>) and overall at least 10 times more efficient than the other
hierarchical algorithms in this study.</p>
</div>
<div class="section" id="timings-as-a-function-of-n-and-d">
<h2>Timings as a Function of <cite>n</cite> and <cite>d</cite><a class="headerlink" href="#timings-as-a-function-of-n-and-d" title="Permalink to this headline">¶</a></h2>
<p>In order to study the run-times as a function dataset size and dimensionality,
let’s consider a series of synthetic benchmarks, each with two Gaussian blobs of size <cite>n/2</cite>
(with i.i.d. coordinates), in a <cite>d</cite>-dimensional space.</p>
<p>Here are the medians of 3-10 timings (depending on the dataset size), in seconds,
on 6 threads:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 30%" />
<col style="width: 5%" />
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>method</p></th>
<th class="head"><p>d</p></th>
<th class="head"><p>10000</p></th>
<th class="head"><p>50000</p></th>
<th class="head"><p>100000</p></th>
<th class="head"><p>500000</p></th>
<th class="head"><p>1000000</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Genie_0.3_approx</p></td>
<td><p>2</p></td>
<td><p>0.17</p></td>
<td><p>0.98</p></td>
<td><p>2.12</p></td>
<td><p>14.93</p></td>
<td><p>33.79</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>5</p></td>
<td><p>0.2</p></td>
<td><p>1.3</p></td>
<td><p>2.87</p></td>
<td><p>22.75</p></td>
<td><p>54.66</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>10</p></td>
<td><p>0.25</p></td>
<td><p>1.69</p></td>
<td><p>3.84</p></td>
<td><p>36.18</p></td>
<td><p>92.03</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>25</p></td>
<td><p>0.29</p></td>
<td><p>1.95</p></td>
<td><p>5.46</p></td>
<td><p>62.25</p></td>
<td><p>158.27</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>50</p></td>
<td><p>0.36</p></td>
<td><p>3.15</p></td>
<td><p>8.15</p></td>
<td><p>81.95</p></td>
<td><p>202.08</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>100</p></td>
<td><p>0.48</p></td>
<td><p>4.6</p></td>
<td><p>12.6</p></td>
<td><p>113.37</p></td>
<td><p>266.64</p></td>
</tr>
<tr class="row-even"><td><p>Genie_0.3_mlpack</p></td>
<td><p>2</p></td>
<td><p>0.04</p></td>
<td><p>0.26</p></td>
<td><p>0.55</p></td>
<td><p>3.03</p></td>
<td><p>6.58</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>5</p></td>
<td><p>0.28</p></td>
<td><p>1.96</p></td>
<td><p>4.46</p></td>
<td><p>28.4</p></td>
<td><p>62.75</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>10</p></td>
<td><p>3.08</p></td>
<td><p>35.54</p></td>
<td><p>92.87</p></td>
<td><p>794.71</p></td>
<td><p>2014.59</p></td>
</tr>
<tr class="row-odd"><td><p>Genie_0.3_nomlpack</p></td>
<td><p>2</p></td>
<td><p>0.16</p></td>
<td><p>2.52</p></td>
<td><p>9.87</p></td>
<td><p>267.76</p></td>
<td><p>1657.86</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>5</p></td>
<td><p>0.14</p></td>
<td><p>2.62</p></td>
<td><p>11.4</p></td>
<td><p>421.46</p></td>
<td><p>2997.11</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>10</p></td>
<td><p>0.15</p></td>
<td><p>3.21</p></td>
<td><p>12.74</p></td>
<td><p>719.33</p></td>
<td><p>4388.26</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>25</p></td>
<td><p>0.28</p></td>
<td><p>6.51</p></td>
<td><p>26.65</p></td>
<td><p>1627.9</p></td>
<td><p>7708.23</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>50</p></td>
<td><p>0.47</p></td>
<td><p>11.97</p></td>
<td><p>54.52</p></td>
<td><p>2175.3</p></td>
<td><p>11346.3</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>100</p></td>
<td><p>1</p></td>
<td><p>26.07</p></td>
<td><p>132.47</p></td>
<td><p>4408.07</p></td>
<td><p>16021.8</p></td>
</tr>
</tbody>
</table>
<p>By default, <cite>mlpack_enabled</cite> is <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code>, which translates
to <code class="docutils literal notranslate"><span class="pre">True</span></code> if the requested metric is Euclidean,  Python package <cite>mlpack</cite> is available,
and <cite>d</cite> is not greater than 6.
The effect of the curse of dimensionality is clearly visible – clustering
in very low-dimensional Euclidean spaces is extremely fast.
On the other hand, the approximate version of Genie can easily cluster
very large datasets. Only the system’s memory limits might become a problem then.</p>
<div class="figure align-default" id="id9">
<a class="reference internal image-reference" href="../_images/timings_g2mg-plot_1.png"><img alt="../_images/timings_g2mg-plot_1.png" src="../_images/timings_g2mg-plot_1.png" style="width: 15cm;" /></a>
<p class="caption"><span class="caption-text">Timings [s] as a function of the dataset size and dimensionality — problem sizes that can be solved during a coffee-break.</span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="timings-as-a-function-of-the-number-of-threads">
<h2>Timings as a Function of the Number of Threads<a class="headerlink" href="#timings-as-a-function-of-the-number-of-threads" title="Permalink to this headline">¶</a></h2>
<p>Recall that the timings are done on a PC with 6 physical cores.
Genie turns out to be nicely parallelisable — as evidenced on
the <code class="docutils literal notranslate"><span class="pre">mnist/digits</span></code> dataset:</p>
<div class="figure align-default" id="id10">
<a class="reference internal image-reference" href="../_images/timings_timings-plot_1.png"><img alt="../_images/timings_timings-plot_1.png" src="../_images/timings_timings-plot_1.png" style="width: 15cm;" /></a>
<p class="caption"><span class="caption-text">Timings [s] as a function of the number of clusters and threads.</span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>The approximate (<cite>exact</cite> = <code class="docutils literal notranslate"><span class="pre">False</span></code>) version of Genie is much faster
than the original one. At the same time, it is still
<a class="reference internal" href="benchmarks_approx.html"><span class="doc">highly compatible</span></a> with it
(at least at higher levels of the cluster hierarchy). Therefore, we
can safely recommend its use in large problem instances.
Most importantly, its performance is not much worse than the K-means method
with small K. Once a complete cluster hierarchy is determined,
partitioning of any cardinality can be extracted in less than 0.34 s on a 1M dataset.
Still, even the exact Genie is amongst the fastest clustering algorithms in the pool.</p>
<p>On top of that, we are also allowed to change our mind about the <cite>gini_threshold</cite>
parameter once the clustering is has been determined. The MST is stored for further
reference and is not recomputed unless needed. Here are the timings for
a first run of the algorithm:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">genieclust</span><span class="o">,</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&quot;worms_2.data.gz&quot;</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">genieclust</span><span class="o">.</span><span class="n">Genie</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gini_threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time elapsed - first run: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">time</span> <span class="n">elapsed</span> <span class="o">-</span> <span class="n">first</span> <span class="n">run</span><span class="p">:</span> <span class="mf">0.589</span>
</pre></div>
</div>
<p>Changing some parameters and re-running the cluster search:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">gini_threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time elapsed - consecutive run: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">time</span> <span class="n">elapsed</span> <span class="o">-</span> <span class="n">consecutive</span> <span class="n">run</span><span class="p">:</span> <span class="mf">0.025</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="noise.html" class="btn btn-neutral float-right" title="Clustering with Noise Points Detection" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="benchmarks_ar.html" class="btn btn-neutral float-left" title="Benchmarks (How Good Is It?)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Marek Gagolewski

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>